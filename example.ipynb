{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key-Value Memory Network for Wikipedia Biography QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "This notebook demonstrates the usage of the Key-Value Memory Network implementation for question answering tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import unidecode\n",
    "\n",
    "from model.memory_network import KVMemoryNetwork\n",
    "from utils.data_utils import Vocab, multihot, tokenize\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "!git clone https://github.com/rlebret/wikipedia-biography-dataset.git\n",
    "!cat wikipedia-biography-dataset/wikipedia-biography-dataset.z?? > tmp.zip\n",
    "!unzip -o tmp.zip\n",
    "!rm tmp.zip\n",
    "\n",
    "# Get titles\n",
    "train_titles = []\n",
    "with open(\"wikipedia-biography-dataset/train/train.title\", \"r\") as file:\n",
    "    for line in file:\n",
    "        train_titles.append(line.rstrip())\n",
    "\n",
    "# Get boxes\n",
    "train_boxes = []\n",
    "with open(\"wikipedia-biography-dataset/train/train.box\", \"r\") as file:\n",
    "    for line in file:\n",
    "        train_boxes.append(line.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_db(titles, boxes):\n",
    "    \"\"\"Create database from titles and boxes.\"\"\"\n",
    "    db = {}  \n",
    "    for i in tqdm(range(len(titles))):\n",
    "        box = boxes[i]\n",
    "        d = {}\n",
    "        for pair in re.findall(r'([a-zA-Z_]+)[0-9]*\\:([\\\\w\\\\d]+)', box):\n",
    "            key, value = pair\n",
    "            key = key.strip()\n",
    "            value = value.strip()\n",
    "            if 'image' not in key:\n",
    "                if key[-1] == '_':\n",
    "                    key = key[:-1]\n",
    "                if key not in d:\n",
    "                    d[key] = value\n",
    "                else:\n",
    "                    d[key] += ' ' + value\n",
    "        if 'office' in d:\n",
    "            db[titles[i]] = d\n",
    "    return db\n",
    "\n",
    "DB = make_db(train_titles, train_boxes)\n",
    "print(f\"Created database with {len(DB)} entries\")\n",
    "\n",
    "def make_vocab(DB):\n",
    "    \"\"\"Create vocabulary from database.\"\"\"\n",
    "    vocab = Vocab()\n",
    "    tokens = tokenize(str(DB))\n",
    "    for t in tqdm(tokens):\n",
    "        vocab.add_word(t)\n",
    "    return vocab\n",
    "\n",
    "VOCAB = make_vocab(DB)\n",
    "print(f\"Created vocabulary with {VOCAB.num_words()} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_formatted_datasets(DB, vocab, train_size=500, test_size=100):\n",
    "    \"\"\"Create training and testing datasets from the biographical database.\"\"\"\n",
    "    raw_data = []\n",
    "    count = 0\n",
    "    \n",
    "    # Process each person in DB\n",
    "    for name, content in DB.items():\n",
    "        if count >= train_size + test_size:\n",
    "            break\n",
    "        person_data = []\n",
    "        for key, value in content.items():\n",
    "            # Store raw strings\n",
    "            question_key = f\"{name} {key}\"\n",
    "            question_value = f\"{name} {value}\"\n",
    "            person_data.append((name, question_key, question_value))\n",
    "        if person_data:\n",
    "            raw_data.append(person_data)\n",
    "            count += 1\n",
    "            if count % 100 == 0:\n",
    "                print(f\"Processed {count} entries\")\n",
    "\n",
    "    # Split into train and test\n",
    "    train_raw = raw_data[:train_size]\n",
    "    test_raw = raw_data[train_size:train_size + test_size]\n",
    "    \n",
    "    # Convert to tensors\n",
    "    train_data = []\n",
    "    for person_data in raw_data[:train_size]:\n",
    "        person_tensors = []\n",
    "        for name, q_key, q_val in person_data:\n",
    "            question = torch.tensor(multihot(name, vocab), dtype=torch.float32)\n",
    "            key_vec = torch.tensor(multihot(q_key, vocab), dtype=torch.float32)\n",
    "            value_vec = torch.tensor(multihot(q_val, vocab), dtype=torch.float32)\n",
    "            person_tensors.append((question, key_vec, value_vec))\n",
    "        if person_tensors:\n",
    "            questions = torch.stack([p[0] for p in person_tensors])\n",
    "            keys = torch.stack([p[1] for p in person_tensors])\n",
    "            values = torch.stack([p[2] for p in person_tensors])\n",
    "            train_data.append((questions, keys, values))\n",
    "            \n",
    "    return train_data, test_raw\n",
    "\n",
    "# Create datasets\n",
    "train_data, test_data = create_formatted_datasets(DB, VOCAB, train_size=500, test_size=100)\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "vocab_size = len(VOCAB._word2index)\n",
    "embed_size = 256\n",
    "\n",
    "model = KVMemoryNetwork(vocab_size, embed_size)\n",
    "model = model.to(device)\n",
    "print(\"Model initialized\")\n",
    "\n",
    "# Train the model\n",
    "losses, accuracies = train_model(\n",
    "    model,\n",
    "    train_data,\n",
    "    num_epochs=10,\n",
    "    learning_rate=0.001,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Plot training curves\n",
    "plot_training_curves(losses, accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering\n",
    "\n",
    "Test the model with some example questions about historical figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, person, model, DB, vocab, device):\n",
    "    \"\"\"Answer a question about a person using the trained model.\"\"\"\n",
    "    if person not in DB:\n",
    "        return \"Person not found in database.\"\n",
    "        \n",
    "    # Process question\n",
    "    q_tensor = torch.tensor(multihot(question, vocab), dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Get person's data\n",
    "    person_data = []\n",
    "    for key, value in DB[person].items():\n",
    "        question_key = f\"{person} {key}\"\n",
    "        person_data.append((question_key, value))\n",
    "        \n",
    "    # Add random people's data for comparison\n",
    "    other_persons = list(set(DB.keys()) - {person})\n",
    "    rand_persons = np.random.choice(other_persons, 2, replace=False)\n",
    "    \n",
    "    # Prepare keys and values\n",
    "    keys = []\n",
    "    values = []\n",
    "    \n",
    "    # Add main person's data\n",
    "    for key, value in person_data:\n",
    "        keys.append(torch.tensor(multihot(key, vocab), dtype=torch.float32))\n",
    "        values.append(torch.tensor(multihot(value, vocab), dtype=torch.float32))\n",
    "    \n",
    "    # Add random persons' data\n",
    "    for p in rand_persons:\n",
    "        for key, value in DB[p].items():\n",
    "            question_key = f\"{p} {key}\"\n",
    "            keys.append(torch.tensor(multihot(question_key, vocab), dtype=torch.float32))\n",
    "            values.append(torch.tensor(multihot(value, vocab), dtype=torch.float32))\n",
    "    \n",
    "    k_tensor = torch.stack(keys).unsqueeze(0).to(device)\n",
    "    v_tensor = torch.stack(values).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Get model prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(q_tensor, k_tensor, v_tensor)\n",
    "        all_values = model.get_value_embeddings(v_tensor.squeeze(0))\n",
    "        similarity = torch.matmul(output, all_values.t())\n",
    "        pred_idx = torch.argmax(similarity).item()\n",
    "    \n",
    "    # Return predicted value\n",
    "    return list(values)[pred_idx]\n",
    "\n",
    "# Test some questions\n",
    "test_questions = [\n",
    "    (\"When was Alexander Hamilton born?\", \"alexander hamilton\"),\n",
    "    (\"What was Alexander Hamilton's party?\", \"alexander hamilton\"),\n",
    "    (\"Where was George Washington born?\", \"george washington\"),\n",
    "    (\"What was Abraham Lincoln's occupation?\", \"abraham lincoln\")\n",
    "]\n",
    "\n",
    "print(\"Testing question answering:\")\n",
    "for question, person in test_questions:\n",
    "    print(f\"\\nQ: {question}\")\n",
    "    answer = answer_question(question, person, model, DB, VOCAB, device)\n",
    "    print(f\"A: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinfo_env_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
